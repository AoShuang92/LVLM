{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7533f640-715a-4945-949c-6fed91992772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sa5u24/safe_lora\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/home/sa5u24/safe_lora'\n",
    "hf_home = os.path.expanduser(\n",
    "    os.getenv(\"HF_HOME\", os.path.join(os.getenv(\"XDG_CACHE_HOME\", \"~/.cache\"), \"huggingface\"))\n",
    ")\n",
    "print(hf_home)\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Replace 'your-hf-token-here' with your actual Hugging Face token\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774fd24c-86ae-4ca3-bf60-a08d53843380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"knkarthick/dialogsum\")\n",
    "dataset_val = dataset['test']\n",
    "print(len(dataset_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75b1c04-ed3e-4da6-ab62-f2d94bfe7561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3026d44f90b42f08832db0fd86a5c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# BitsAndBytesConfig int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\",\n",
    "            # attn_implementation=\"flash_attention_2\", # not supported for training\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            quantization_config=bnb_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "\n",
    "lora_config = LoraConfig(\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        r=8,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f1c27c-3d32-41b8-a379-c8eeb7d9dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_qa(example):\n",
    "    \"\"\"Generates a standardized message to prompt the model with an instruction, optional input and a\n",
    "    'response' field.\"\"\"\n",
    "    \n",
    "    return f\"### Context:Summarize the following dialogue as briefly and precisely as possible. Focus only on the main points and avoid unnecessary details: \\n### Dialogue:\\n{example['dialogue']}\\n\\n### Summary:\\n\"\n",
    "\n",
    "\n",
    "def preprocess_function(model, example: dict, tokenizer=tokenizer, max_length=512, mask_inputs: bool = True):\n",
    "    \n",
    "    \"\"\"Processes a single sample.\"\"\"\n",
    "    inputs = generate_prompt_qa(example)\n",
    "    # print(\"inputs\", inputs)\n",
    "    model_inputs = tokenizer(inputs, max_length=max_length, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate text with the model\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=max_length)\n",
    "\n",
    "    # Trim the generated ids to remove the input ids\n",
    "    trimmed_generated_ids = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    # Decode the output text\n",
    "    output_text = tokenizer.batch_decode(\n",
    "        trimmed_generated_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text[0]  # Return the first decoded output text\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33baf8e2-af47-4332-ad3f-fad77d284c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa5u24/anaconda3/envs/lit_llama/lib/python3.10/site-packages/transformers/generation/utils.py:1935: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import torch\n",
    "from nltk.translate.meteor_score import meteor_score, single_meteor_score\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "import requests\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "all_pred = []\n",
    "all_ans = []\n",
    "i = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for sample in dataset_val:\n",
    "        output = preprocess_function(model, sample)\n",
    "        ans = sample['summary']\n",
    "        all_pred.append(output)\n",
    "        all_ans.append(ans)\n",
    "        i+= 1\n",
    "        if i>49:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de74070-1ac1-4d06-84bb-d4b23f435ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_pred), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "099d99cd-2bfd-4e8a-bab2-ded5cefb3a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: Ms. Dawson is asked to take dictation for a memo that outlines a new office policy. The policy restricts all office communications to email and official memos, and makes use of Instant Messaging strictly prohibited during working hours. Employees who violate the policy will face disciplinary action, including termination.\n",
      "ans: Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.\n",
      "pred: Ms. Dawson is requested to take a dictation for a memo that outlines a new policy restricting the use of Instant Messaging in the office. The policy applies to both internal and external communications, and any employee found using Instant Messaging will face consequences, including termination. The memo must be distributed to all employees by 4 pm.\n",
      "ans: In order to prevent employees from wasting time on Instant Message programs, #Person1# decides to terminate the use of those programs and asks Ms. Dawson to send out a memo to all employees by the afternoon.\n",
      "pred: The CEO has implemented a new policy that restricts the use of Instant Messaging during working hours in the office. Employees are prohibited from using Instant Messaging for any communication, both internal and external. Any violation will result in warnings, probation, and termination. The memo must be typed up and distributed to all employees by 4 pm.\n",
      "ans: Ms. Dawson takes a dictation for #Person1# about prohibiting the use of Instant Message programs in the office. They argue about its reasonability but #Person1# still insists.\n",
      "pred: The dialogue is between two people, #Person1# and #Person2#, discussing the traffic jam that #Person2# encountered on the way to work. #Person1# suggests that #Person2# should consider using public transportation instead of driving, citing its environmental benefits and reduced stress levels. #Person2# agrees that it's a good idea and mentions that they will start biking to work when the weather is nicer.\n",
      "ans: #Person2# arrives late because of traffic jam. #Person1# persuades #Person2# to use public transportations to keep healthy and to protect the environment.\n",
      "pred: Person 1 notices that person 2 is late and suggests taking public transportation to avoid traffic congestion. Person 2 agrees that it's a good idea and mentions that they will consider using public transportation to work. They also mention that they will miss the freedom of driving, but will try biking instead.\n",
      "ans: #Person2# decides to follow #Person1#'s suggestions on quitting driving to work and will try to use public transportations.\n",
      "pred: Person 2 is stuck in traffic again and is considering using public transportation to get to work. Person 1 suggests this as a solution, pointing out that it's better for the environment and would be less stressful. Person 2 agrees and mentions that they would miss having the freedom of driving, but is willing to consider biking as an alternative.\n",
      "ans: #Person2# complains to #Person1# about the traffic jam, #Person1# suggests quitting driving and taking public transportation instead.\n",
      "pred: The speaker is surprised to hear that Masha and Hero are getting divorced after being together for a long time. The speaker does not have much information about the reason for the divorce, but they know that Masha and Hero are filing for divorce and that Masha seems to be handling it quietly. The speaker wonders who will get custody of the children and when the divorce will be finalized.\n",
      "ans: #Person1# tells Kate that Masha and Hero get divorced. Kate is surprised because she thought they are perfect couple.\n",
      "pred: The dialogue is about Kate informing Person2 that Masha and Hero are getting divorced. Person1 provides some details about the separation, including that they are filing for divorce and have already reached an agreement on custody of their children. Person2 is surprised and expresses disbelief, asking when the divorce will be finalized.\n",
      "ans: #Person1# tells Kate that Masha and Hero are getting a peaceful divorce. Kate feels surprised and asks about their kids.\n",
      "pred: The dialogue is about Kate informing Person2 that Masha and Hero are getting divorced. Person1 mentions that they are separating for 2 months before filing for divorce and that there is no quarreling about who gets custody of the children. Person2 is surprised and cannot believe that the perfect couple, Masha and Hero, are getting divorced. Person1 mentions that the divorce will be finalized early in the New Year.\n",
      "ans: #Person1# and Kate talk about the divorce between Masha and Hero. Kate feels surprised because she thought they are well matched\n",
      "pred: Person 1 brings a gift to Person 2's birthday party and asks to dance with them. Person 2 is happy and invites Person 1 to enjoy the party. Person 1 thanks them and compliments their appearance, and they both agree to have a drink together to celebrate.\n",
      "ans: #Person1# and Brian are at the birthday party of Brian. Brian thinks #Person1# looks great and is popular.\n",
      "pred: Person 1 brings a gift to Person 2's birthday party and asks to dance. Person 2 is happy to see Person 1 and invites them to enjoy the party. Person 1 thanks Person 2 for their kind words and suggests having a drink together to celebrate.\n",
      "ans: #Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
      "pred: Person1 brings a gift to Person2's birthday party and asks to dance with them. Person2 is happy and invites Person1 to enjoy the party. They exchange pleasantries and compliments, with Person1 expressing gratitude for the invitation and the gift. They also suggest having a drink together to celebrate Person2's birthday.\n",
      "ans: #Person1# has a dance with Brian at Brian's birthday party. Brian thinks #Person1# looks great and is popular.\n",
      "pred: The two people are at the Olympic park, specifically in the stadium. They are discussing the size of the park and the stadium, with #Person1# expressing surprise at its size. #Person2# provides information on the number of seats in the stadium (5000) and mentions the presence of signs in English for foreign visitors.\n",
      "ans: #Person1# is surprised at the Olympic Stadium'volume, capacity and interior setting to #Person1#.\n",
      "pred: In this dialogue, Person1 expresses amazement at the size of the Olympic park. Person2 replies that the stadium, the center of the park, is to be finished in June. Person1 asks how many seats are in the stand and Person2 answers that there are 5000 seats in total. Person1 is surprised by the size of the park and stadium, and Person2 mentions that there are signs in English for foreign visitors.\n",
      "ans: #Person2# shows #Person1# around the constructing Olympic stadium and introduces the stadium.\n",
      "pred: The dialogue takes place in an Olympic park, where #Person1# is amazed by the size of the park. #Person2# explains that the stadium is to be finished in June and has 5000 seats. #Person1# is impressed by the size of the tracks and jumping pit, and #Person2# mentions that many signs are placed with English translations for foreign visitors.\n",
      "ans: #Person2# introduces the Olympic Stadium's finishing time, capacity and interior setting to #Person1#.\n",
      "pred: The speaker has decided to quit their job and start their own business. However, they are unaware of the complexity of writing a business plan, which includes an executive summary, description of the company, goods or services, market analysis, strategy and implementation, and financial analysis.\n",
      "ans: #Person1# wants to create a company and is going to write a business plan. #Person2# gives #Person1# suggestions on how to summarise business ideas, describe the service, differ from competitors and attract investment in a good business plan. #Person1# decides to stick to the old job.\n",
      "pred: The speaker has decided to quit their job and start their own business. They are not aware of the complexity of creating a business plan and the various sections it involves, including an executive summary, company description, goods and services, market analysis, strategy and implementation, and financial analysis. They are considering giving up on the idea of starting their own business due to the perceived difficulty.\n",
      "ans: #Person1# abandons the idea of creating a company after #Person2# explains what a business plan includes. #Person2# specifies that a well-written business plan includes an executive summary, goods and service description, strategy and implementation, and financial analysis.\n",
      "pred: The main points of the dialogue are:\n",
      "\n",
      "1. The speaker has had enough of their current job and wants to start their own business.\n",
      "2. They plan to write a business plan, but are unaware of the complexity of the task.\n",
      "3. A well-written business plan includes an executive summary, description of the company, goods or services, market analysis, strategy and implementation, and financial analysis.\n",
      "4. The speaker is intimidated by the amount of work involved in creating a business plan.\n",
      "ans: #Person1# wants to start #Person1#'s own business, but #Person2# warns #Person1# of the hassle. #Person2# tells #Person1# what is needed in a business plan and #Person1# decides to stick to the old job for now.\n",
      "pred: Person 2 is scratching excessively and feels weak and lightheaded. Person 1 examines Person 2 and suspects they have chicken pox, which is contagious. Person 2 dismisses the idea and plans to see a doctor. Person 1 is concerned about the risk of infection and advises Person 2 to take precautions.\n",
      "ans: #Person2# feels itchy. #Person1# doubts it is chicken pox and asks #Person2# to get away. #Person2# doesn't believe it.\n",
      "pred: The dialogue is between two people, #Person1# and #Person2#, where #Person2# is experiencing itchiness and lightheadedness. #Person1# suspects that #Person2# may have chicken pox and is concerned about being contagious. #Person2# tries to downplay the symptoms and suggests seeing a doctor. #Person1# is worried about the severity of the illness and the potential for complications.\n",
      "ans: #Person1# suspects that #Person2# has chicken pox and wants to keep away from #Person2#. #Person2# thinks #Person1# is exaggerating.\n",
      "pred: The dialogue is about two people, #Person1# and #Person2#, discussing #Person2#'s sudden itchiness and possible illness. #Person1# suspects that #Person2# may have chicken pox and is concerned about being contagious. #Person2# tries to downplay the situation and suggests seeing a doctor to get a proper diagnosis.\n",
      "ans: #Person1# thinks #Person2# has chicken pox and warns #Person2# about the possible hazards but #Person2# thinks it will be fine.\n",
      "pred: The dialogue is between a front desk clerk and a guest who is checking out. The guest notices an unexpected charge on their bill and questions the clerk about it. The clerk apologizes and confirms that there has been a mistake, offering to correct the bill.\n",
      "ans: #Person2# is checking out and asks #Person1# for the bill. #Person1# gives #Person2# a wrong bill at first then corrects it.\n",
      "pred: The dialogue is between a hotel staff member and a guest who is checking out. The guest notices an unexpected charge on their bill and asks the staff member about it. The staff member apologizes and checks with the department concerned to correct the mistake.\n",
      "ans: #Person1# helps #Person2# correct a mischarged bill on laundry service and helps #Person2# check out.\n",
      "pred: Person 2 is checking out of a hotel and discovers an unexpected charge on their bill. They bring it to the attention of Person 1, who apologizes and promises to correct the mistake.\n",
      "ans: #Person2# finds #Person2# being mischarged. #Person1# corrects the bill and #Person2# pays for it.\n",
      "pred: The speaker's wife has found out about their affair with their secretary and is threatening to divorce them. The speaker admits to cheating and swears to be faithful from now on. They ask for the other person's help in persuading their wife to reconsider the divorce.\n",
      "ans: #Person1# is begging Steven to persuade his wife not to divorce him. Steven agrees.\n",
      "pred: Steven's wife has found out about his affair with his secretary, and she is planning to divorce him. Steven admits that he was wrong and swears to be faithful to his wife from now on. His friend tries to persuade his wife to reconsider the divorce, but Steven's promise of loyalty is the main condition.\n",
      "ans: Steve will try to persuade #Person1#'s wife not to divorce #Person1# as #Person1# swears to remain faithful forever.\n",
      "pred: The speaker's wife has discovered an affair with his secretary, and the speaker is seeking help to prevent the divorce. The speaker admits to cheating and promises to be faithful to his wife from now on.\n",
      "ans: #Person1# begs Steven's to persuade #Person1#'s wife not to divorce him, and Steven agrees.\n",
      "pred: Person 1 asks Person 2 to name someone with sound character, and Person 2 responds by mentioning Abraham Lincoln. Person 1 highlights Lincoln's integrity, determination, and fight for equal rights, while Person 2 expresses admiration for Lincoln's character and humility.\n",
      "ans: #Person1# and #Person2# are talking about Abraham Lincoln. They think he was a noble man.\n",
      "pred: In this dialogue, Person1 asks Person2 to name someone with sound character. Person2 responds by mentioning Abraham Lincoln, citing his reputation for integrity, determination, and fighting for equal rights. Person1 agrees, highlighting Lincoln's perseverance and vision.\n",
      "ans: #Person2# admires Abraham Lincoln for his perseverance, courage and humility.\n",
      "pred: Person 2 names Abraham Lincoln as a man of sound character, citing his reputation for integrity, perseverance, and commitment to social justice. They discuss Lincoln's determination to achieve his goals despite numerous setbacks and his courage in advocating for equal rights.\n",
      "ans: #Person1# and #Person2# talk about Abraham Lincoln and his glorious history. They both admire him.\n",
      "pred: Person 1 asks Person 2 where they are going for their trip, and Person 2 replies that they are considering Hebei. Person 1 expresses concern about the severe sandstorms in the north of China, including Hebei, and how they can affect people's health. Person 2 agrees that sandstorms are troublesome for everyone.\n",
      "ans: #Person2# plans to have a trip in Hebei but #Person1# says there are sandstorms in there.\n",
      "pred: The dialogue is about a trip to Hebei, which is located in the north of China. Person 1 expresses concern about the severe sandstorms in the area, which can cause respiratory tract infections due to the sand getting into people's noses and throats, leading to irritation. Person 2 agrees that sandstorms are trouble for everyone.\n",
      "ans: #Person1# tells #Person2# Hebei was experiencing severe sandstorms and sandstorms threaten people's health.\n",
      "pred: The dialogue is about two people discussing a trip to Hebei province in China. Person 1 expresses concern about the severe sandstorms in the north of China, including Hebei, and Person 2 confirms the information. Person 1 explains that the sandstorms can cause respiratory problems for people living in these areas, including irritation in the nose and throat.\n",
      "ans: #Person2# wants to travel to Hebei but #Person1# informs #Person2# of terrible sandstorms there.\n",
      "pred: Person 1 invites Person 2 to their birthday party and Person 2 gives a gift. Person 1 is happy and appreciative of the gift, which is a remote car model of their favorite brand. Person 2 explains that they were struggling with whether to give the gift to Person 1 or keep it for themselves, but ultimately decided to give it to Person 1.\n",
      "ans: #Person2# comes to the birthday party of Francis and sends him a remote car model.\n",
      "pred: Person1 hosts a birthday party and invites Person2. Person2 gives a gift to Person1, which is a remote car model of Person1's favorite brand. Person1 thanks Person2 and opens the gift, expressing appreciation. Person2 explains that they were struggling whether to give the gift to Person1 or keep it for themselves, but is glad they gave it to Person1.\n",
      "ans: #Person2# gives Francis a car model that both of them love as a birthday gift.\n",
      "pred: The dialogue is about a person, Francis, who is celebrating their birthday and receiving a gift from a friend. The friend, who is struggling with whether to give the gift to Francis or keep it for themselves, ultimately decides to give it to Francis. Francis is grateful and appreciative of the gift, which is a remote car model.\n",
      "ans: #Person2# gives Francis a nice car model as a birthday gift and Francis appreciates it.\n",
      "pred: Tony made a mistake by cheating on a test, and he feels ashamed and worried about the consequences of his actions. He confides in Steven, who advises him to study hard and learn from his mistakes.\n",
      "ans: Tony got caught cheating and feels ashamed. Steven tells him to learn from it and study hard.\n",
      "pred: Person2 confides in Person1 about getting caught cheating on an exam. They are ashamed and worried about their father's reaction. Person1 advises Person2 to study hard and learn from their mistakes.\n",
      "ans: Tony tells Steven that he failed a class because of cheating and he feels awful.\n",
      "pred: Tony made a big mistake by cheating on an exam, which he got caught for. He feels ashamed and afraid of his father's reaction. Steven advises Tony to study hard instead of cheating, and reminds him to learn from his mistakes.\n",
      "ans: Tony tells Steven that he cheated on the exam and realized his mistake.\n",
      "pred: The dialogue takes place between two people, #Person1# and #Person2#, who are discussing the time. #Person1# is leaving and wants to catch the 9:30 train, but #Person2# tells them they have plenty of time and it's only ten to nine.\n",
      "ans: #Person1# is catching a train. Tom asks #Person1# not to hurry.\n",
      "pred: The conversation is between two people, #Person1# and #Person2#, about the time. #Person1# is leaving and wants to know the time, which is 9:40 by #Person2#'s watch. #Person1# is planning to catch a train at 9:30 and #Person2# tells them they have plenty of time to get to the station, which is close by.\n",
      "ans: #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "pred: In this dialogue, Person1 asks Person2 what time it is and learns that it is ten to nine. Person1 then reveals that they must catch a train at nine-thirty and expresses a sense of urgency. Person2 reassures Person1 that they have plenty of time and offers to walk with them to the railway station, which is nearby.\n",
      "ans: #Person1# is rushing to catch a train but Tom thinks it isn't necessary.\n",
      "pred: The dialogue revolves around #Person1#'s difficulty in adjusting their life. #Person2# offers various pieces of advice, including getting enough sleep, drinking less wine, exercising regularly, and not worrying too much about the future.\n",
      "ans: #Person1# wants to adjust #Person1#'s life and #Person2# suggests #Person1# be positive and stay healthy.\n",
      "pred: The dialogue revolves around #Person1#'s difficulty in adjusting their life, including poor sleep quality, excessive wine consumption, and feelings of tiredness. #Person2# offers various pieces of advice, including getting enough sleep, exercising regularly, and not worrying too much about the future.\n",
      "ans: #Person1# has a bad lifestyle. #Person2# kindly advises #Person1# to be positive.\n",
      "pred: The dialogue is between two people, #Person1# and #Person2#, where #Person1# is feeling unwell and is seeking advice. #Person2# advises #Person1# to get enough sleep, avoid drinking too much wine, and exercise regularly. #Person1# also mentions feeling a shadow of death in front of them, to which #Person2# replies that they are young and will make a great contribution to the world.\n",
      "ans: #Person2# hopes #Person1# will become healthy and positive.\n",
      "pred: Person1 invites Person2 to a party hosted by their friend Ruojia, who recently got married. Person2 expresses their surprise and happiness for Ruojia, and Person1 mentions that they saw the news on Twitter and Ruojia sent an email about it. Person2 says they will bring a tea set as a gift, and Person1 agrees to bring a pair of wineglasses and a card to wish Ruojia happiness in her marriage.\n",
      "ans: #Person1# tells #Person2# that Ruojia is married and will have a party tonight. #Person2#'s surprised to know that. They will bring their gifts to bless her.\n",
      "pred: The dialogue is about a party invitation to Ruojia's wedding. Person1 invites Person2 to the party and provides some background information about Ruojia's marriage. Person2 expresses their happiness for Ruojia and asks if they should bring something. Person1 suggests bringing a pair of wineglasses and a card, while Person2 offers to buy a tea set.\n",
      "ans: #Person2# is surprised to know from #Person1# that Ruojia is married. Then #Person2# finds Ruojia has sent an email about it. They will go to Ruojia's party and give their presents to her.\n",
      "pred: The dialogue is between two people, #Person1# and #Person2#, about a mutual friend, Ruojia, who has got married. They are discussing whether they received an email about the wedding and what they will bring to the party tonight. #Person1# mentions that they saw the news on Twitter and received an email about it, while #Person2# says they didn't receive the email and will buy a tea set to bring to the party.\n",
      "ans: #Person2# is surprised that Ruojia's married. #Person1# and #Person2# will go to her party and give their presents to wish her a happy marriage.\n",
      "pred: The dialogue is between two people, #Person1# and #Person2#, about a prank involving pulling on a strip of paper and peeling off the back. #Person1# thinks it's fun and wants to do it to make enemies, while #Person2# thinks it's cruel and doesn't want to participate.\n",
      "ans: #Person2# at first thinks #Person1#'s behaviour cruel but finally joins #Person1#.\n",
      "pred: The dialogue is between two people, #Person1# and #Person2#, about peeling off a strip of tape and making fun of two people, possibly elderly or gender non-conforming individuals, who are walking towards them. #Person1# is determined to have fun and make fun of these people, while #Person2# is hesitant and finds it cruel.\n",
      "ans: #Person1# plans on playing a trick to others. #Person2# thinks it's cruel at first but then joins.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_pred)):\n",
    "    print(\"pred:\", all_pred[i])\n",
    "    print(\"ans:\", all_ans[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738f5538-a4ec-45c4-8b48-3da3b054f775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sa5u24/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/sa5u24/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sa5u24/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE: {'rouge1': 0.23509992758038786, 'rouge2': 0.06382929432629775, 'rougeL': 0.17801888955905137, 'rougeLsum': 0.1792074345243292}\n",
      "BLEU: {'bleu': 0.0465758491073283, 'precisions': [0.19181247936612744, 0.06814367237327962, 0.031410037555479685, 0.011462313303230288], 'brevity_penalty': 1.0, 'length_ratio': 2.4154704944178627, 'translation_length': 3029, 'reference_length': 1254}\n",
      "METEOR: {'meteor': 0.29362818643297}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "# Load the metrics\n",
    "meteor = load(\"meteor\")\n",
    "bleu = load(\"bleu\")\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "rouge_results = rouge.compute(predictions=all_pred, references=all_ans)\n",
    "bleu_result = bleu.compute(predictions=all_pred, references=all_ans)\n",
    "meteor_result = meteor.compute(predictions=all_pred, references=all_ans)\n",
    "\n",
    "print(\"ROUGE:\", rouge_results)\n",
    "print(\"BLEU:\", bleu_result)\n",
    "print(\"METEOR:\", meteor_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b64e232-0d66-475e-8d54-704f562e634c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92027eba-0c7c-4a75-8620-416cc22ff670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.26668292872361765, 'rouge2': 0.056467263122369, 'rougeL': 0.19906030995322818, 'rougeLsum': 0.1992574206341532}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "rouge_results = rouge.compute(predictions= all_pred, references=all_ans)\n",
    "print(rouge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51a9c15-8ba9-472e-8865-0933f8cc76fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17225561531161027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa5u24/anaconda3/envs/lit_llama/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/sa5u24/anaconda3/envs/lit_llama/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/sa5u24/anaconda3/envs/lit_llama/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu_score = corpus_bleu(all_ans, all_pred, weights=(1.0, 0.0, 0.0, 0.0))\n",
    "print(bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44040704-9429-4c0f-ab80-151202715183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17225561531161027 2.2250738585072626e-308\n"
     ]
    }
   ],
   "source": [
    "bleu_score = corpus_bleu(all_ans, all_pred, weights=(1.0, 0.0, 0.0, 0.0))\n",
    "bleu_score_4 = corpus_bleu(all_ans, all_pred, weights=(0.0, 0.0, 0.0, 1.0))\n",
    "print(bleu_score, bleu_score_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7144d84-786d-4955-8384-924944a26df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sa5u24/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/sa5u24/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24150637565762811\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "m_score=0\n",
    "for line in zip(all_ans, all_pred):\n",
    "    ref = word_tokenize(line[0])\n",
    "    hypo = word_tokenize(line[1])\n",
    "    m_score += meteor_score([ref], hypo)\n",
    "meteors = m_score/len(all_ans)\n",
    "print(meteors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4cad4-712f-4ec2-ba85-3c7b73b19353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
