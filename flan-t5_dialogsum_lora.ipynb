{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afe47951-6b54-4250-b007-d9a420437542",
   "metadata": {},
   "source": [
    "zero_shot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e31c94e-d3b0-47da-b2b5-ff2bedb71397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: #Person1#: I need to take a dictation for you.\n",
      "ans: Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.\n",
      "pred: #Person1#: I need to take a dictation for you.\n",
      "ans: In order to prevent employees from wasting time on Instant Message programs, #Person1# decides to terminate the use of those programs and asks Ms. Dawson to send out a memo to all employees by the afternoon.\n",
      "pred: #Person1#: I need to take a dictation for you.\n",
      "ans: Ms. Dawson takes a dictation for #Person1# about prohibiting the use of Instant Message programs in the office. They argue about its reasonability but #Person1# still insists.\n",
      "pred: The traffic jam at the Carrefour intersection is a problem.\n",
      "ans: #Person2# arrives late because of traffic jam. #Person1# persuades #Person2# to use public transportations to keep healthy and to protect the environment.\n",
      "pred: The traffic jam at the Carrefour intersection is a problem.\n",
      "ans: #Person2# decides to follow #Person1#'s suggestions on quitting driving to work and will try to use public transportations.\n",
      "pred: The traffic jam at the Carrefour intersection is a problem.\n",
      "ans: #Person2# complains to #Person1# about the traffic jam, #Person1# suggests quitting driving and taking public transportation instead.\n",
      "pred: Masha and Hero are getting divorced.\n",
      "ans: #Person1# tells Kate that Masha and Hero get divorced. Kate is surprised because she thought they are perfect couple.\n",
      "pred: Masha and Hero are getting divorced.\n",
      "ans: #Person1# tells Kate that Masha and Hero are getting a peaceful divorce. Kate feels surprised and asks about their kids.\n",
      "pred: Masha and Hero are getting divorced.\n",
      "ans: #Person1# and Kate talk about the divorce between Masha and Hero. Kate feels surprised because she thought they are well matched\n",
      "pred: #Person1#: Happy birthday, Brian. #Person2#: I'm so happy you're having a good time. #Person1#: Thank you, I'm sure you look great today. #Person2#: Thank you, I'm sure you look great. #Person1#: Thank you, I'm sure you look great today. #Person2#: Thank you, I'm sure you look great today. #Person1#: Thank you, I'm sure you look great today. #Person2#: Thank you, I'm sure you look great today. #Person1#: Thank you, I'm sure you look great today.\n",
      "ans: #Person1# and Brian are at the birthday party of Brian. Brian thinks #Person1# looks great and is popular.\n",
      "pred: #Person1#: Happy birthday, Brian. #Person2#: I'm so happy you're having a good time. #Person1#: Thank you, I'm sure you look great today. #Person2#: Thank you, I'm sure you look great. #Person1#: Thank you, I'm sure you look great today. #Person2#: Thank you, I'm sure you look great today. #Person1#: Thank you, I'm sure you look great today. #Person2#: Thank you, I'm sure you look great today. #Person1#: Thank you, I'm sure you look great today.\n",
      "ans: #Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
      "pred: #Person1#: Happy birthday, Brian. #Person2#: I'm so happy you're having a good time. #Person1#: Thank you, I'm sure you look great today. #Person2#: Thank you, I'm sure you look great. #Person1#: Thank you, I'm sure you look great today. #Person2#: Thank you, I'm sure you look great today. #Person1#: Thank you, I'm sure you look great today. #Person2#: Thank you, I'm sure you look great today. #Person1#: Thank you, I'm sure you look great today.\n",
      "ans: #Person1# has a dance with Brian at Brian's birthday party. Brian thinks #Person1# looks great and is popular.\n",
      "pred: The Olympic park is a huge stadium.\n",
      "ans: #Person1# is surprised at the Olympic Stadium'volume, capacity and interior setting to #Person1#.\n",
      "pred: The Olympic park is a huge stadium.\n",
      "ans: #Person2# shows #Person1# around the constructing Olympic stadium and introduces the stadium.\n",
      "pred: The Olympic park is a huge stadium.\n",
      "ans: #Person2# introduces the Olympic Stadium's finishing time, capacity and interior setting to #Person1#.\n",
      "pred: #Person1#: I am done working for a company that is taking me nowhere! #Person2#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write\n",
      "ans: #Person1# wants to create a company and is going to write a business plan. #Person2# gives #Person1# suggestions on how to summarise business ideas, describe the service, differ from competitors and attract investment in a good business plan. #Person1# decides to stick to the old job.\n",
      "pred: #Person1#: I am done working for a company that is taking me nowhere! #Person2#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write\n",
      "ans: #Person1# abandons the idea of creating a company after #Person2# explains what a business plan includes. #Person2# specifies that a well-written business plan includes an executive summary, goods and service description, strategy and implementation, and financial analysis.\n",
      "pred: #Person1#: I am done working for a company that is taking me nowhere! #Person2#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write up a business plan, get some investors and start working for myself! #Person1#: Well, that's exactly what I am going to do! I am going to write\n",
      "ans: #Person1# wants to start #Person1#'s own business, but #Person2# warns #Person1# of the hassle. #Person2# tells #Person1# what is needed in a business plan and #Person1# decides to stick to the old job for now.\n",
      "pred: #Person1#: I'm scratching so much. I can't stand it anymore. #Person2#: I think I have chicken pox. I'm contagious. #Person1#: I'm a biohazard.\n",
      "ans: #Person2# feels itchy. #Person1# doubts it is chicken pox and asks #Person2# to get away. #Person2# doesn't believe it.\n",
      "pred: #Person1#: I'm scratching so much. I can't stand it anymore. #Person2#: I think I have chicken pox. I'm contagious. #Person1#: I'm a biohazard.\n",
      "ans: #Person1# suspects that #Person2# has chicken pox and wants to keep away from #Person2#. #Person2# thinks #Person1# is exaggerating.\n",
      "pred: #Person1#: I'm scratching so much. I can't stand it anymore. #Person2#: I think I have chicken pox. I'm contagious. #Person1#: I'm a biohazard.\n",
      "ans: #Person1# thinks #Person2# has chicken pox and warns #Person2# about the possible hazards but #Person2# thinks it will be fine.\n",
      "pred: #Person1#: Good morning. I'm checking out today. I'm in Room 309. I'm checking out today. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'\n",
      "ans: #Person2# is checking out and asks #Person1# for the bill. #Person1# gives #Person2# a wrong bill at first then corrects it.\n",
      "pred: #Person1#: Good morning. I'm checking out today. I'm in Room 309. I'm checking out today. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'\n",
      "ans: #Person1# helps #Person2# correct a mischarged bill on laundry service and helps #Person2# check out.\n",
      "pred: #Person1#: Good morning. I'm checking out today. I'm in Room 309. I'm checking out today. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'm checking out today. I'm in Room 309. I'\n",
      "ans: #Person2# finds #Person2# being mischarged. #Person1# corrects the bill and #Person2# pays for it.\n",
      "pred: #Person1#: I need your help.\n",
      "ans: #Person1# is begging Steven to persuade his wife not to divorce him. Steven agrees.\n",
      "pred: #Person1#: I need your help.\n",
      "ans: Steve will try to persuade #Person1#'s wife not to divorce #Person1# as #Person1# swears to remain faithful forever.\n",
      "pred: #Person1#: I need your help.\n",
      "ans: #Person1# begs Steven's to persuade #Person1#'s wife not to divorce him, and Steven agrees.\n",
      "pred: I think Abraham Lincoln is a great man or woman of sound character.\n",
      "ans: #Person1# and #Person2# are talking about Abraham Lincoln. They think he was a noble man.\n",
      "pred: I think Abraham Lincoln is a great man or woman of sound character.\n",
      "ans: #Person2# admires Abraham Lincoln for his perseverance, courage and humility.\n",
      "pred: I think Abraham Lincoln is a great man or woman of sound character.\n",
      "ans: #Person1# and #Person2# talk about Abraham Lincoln and his glorious history. They both admire him.\n",
      "pred: The sandstorms in China are causing a lot of health problems for people in the north of China.\n",
      "ans: #Person2# plans to have a trip in Hebei but #Person1# says there are sandstorms in there.\n",
      "pred: The sandstorms in China are causing a lot of health problems for people in the north of China.\n",
      "ans: #Person1# tells #Person2# Hebei was experiencing severe sandstorms and sandstorms threaten people's health.\n",
      "pred: The sandstorms in China are causing a lot of health problems for people in the north of China.\n",
      "ans: #Person2# wants to travel to Hebei but #Person1# informs #Person2# of terrible sandstorms there.\n",
      "pred: The gift is a remote car model and a brand new remote car model.\n",
      "ans: #Person2# comes to the birthday party of Francis and sends him a remote car model.\n",
      "pred: The gift is a remote car model and a brand new remote car model.\n",
      "ans: #Person2# gives Francis a car model that both of them love as a birthday gift.\n",
      "pred: The gift is a remote car model and a brand new remote car model.\n",
      "ans: #Person2# gives Francis a nice car model as a birthday gift and Francis appreciates it.\n",
      "pred: #Person1#: Hi, Steven.\n",
      "ans: Tony got caught cheating and feels ashamed. Steven tells him to learn from it and study hard.\n",
      "pred: #Person1#: Hi, Steven.\n",
      "ans: Tony tells Steven that he failed a class because of cheating and he feels awful.\n",
      "pred: #Person1#: Hi, Steven.\n",
      "ans: Tony tells Steven that he cheated on the exam and realized his mistake.\n",
      "pred: The train is about to leave.\n",
      "ans: #Person1# is catching a train. Tom asks #Person1# not to hurry.\n",
      "pred: The train is about to leave.\n",
      "ans: #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "pred: The train is about to leave.\n",
      "ans: #Person1# is rushing to catch a train but Tom thinks it isn't necessary.\n",
      "pred: Person1: I'm not sure how to adjust my life.\n",
      "ans: #Person1# wants to adjust #Person1#'s life and #Person2# suggests #Person1# be positive and stay healthy.\n",
      "pred: Person1: I'm not sure how to adjust my life.\n",
      "ans: #Person1# has a bad lifestyle. #Person2# kindly advises #Person1# to be positive.\n",
      "pred: Person1: I'm not sure how to adjust my life.\n",
      "ans: #Person2# hopes #Person1# will become healthy and positive.\n",
      "pred: Ruojia got married yesterday.\n",
      "ans: #Person1# tells #Person2# that Ruojia is married and will have a party tonight. #Person2#'s surprised to know that. They will bring their gifts to bless her.\n",
      "pred: Ruojia got married yesterday.\n",
      "ans: #Person2# is surprised to know from #Person1# that Ruojia is married. Then #Person2# finds Ruojia has sent an email about it. They will go to Ruojia's party and give their presents to her.\n",
      "pred: Ruojia got married yesterday.\n",
      "ans: #Person2# is surprised that Ruojia's married. #Person1# and #Person2# will go to her party and give their presents to wish her a happy marriage.\n",
      "pred: #Person1#: Okay.\n",
      "ans: #Person2# at first thinks #Person1#'s behaviour cruel but finally joins #Person1#.\n",
      "pred: #Person1#: Okay.\n",
      "ans: #Person1# plans on playing a trick to others. #Person2# thinks it's cruel at first but then joins.\n",
      "pred: #Person1#: Okay.\n",
      "ans: #Person1# is about to make a prank. #Person2# thinks it's cruel at first but then joins.\n",
      "pred: Mike's sister is tall and pretty.\n",
      "ans: Mike is describing his sister to #Person1#.\n",
      "pred: Mike's sister is tall and pretty.\n",
      "ans: Mike describes to #Person1# his sister's characters and personality.\n",
      "pred: Mike's sister is tall and pretty.\n",
      "ans: #Person1# asks Mike about his sister.\n",
      "pred: #Person1#: I have a headache. #Person2#: I think you have a small fever.\n",
      "ans: #Person1# feels sick and #Person2# gives #Person1# a check-up.\n",
      "pred: #Person1#: I have a headache. #Person2#: I think you have a small fever.\n",
      "ans: #Person2# finds that #Person1# has a fever and says #Person1# should've called in sick earlier.\n",
      "pred: #Person1#: I have a headache. #Person2#: I think you have a small fever.\n",
      "ans: #Person2# checks #Person1#'s physical condition and finds #Person1# has a fever.\n",
      "pred: #Person1#: I'd like to buy a new mobile phone.\n",
      "ans: #Person1# helps #Person2# to choose a new phone.\n",
      "pred: #Person1#: I'd like to buy a new mobile phone.\n",
      "ans: #Person2# wants to buy a new mobile phone from #Person1#.\n",
      "pred: #Person1#: I'd like to buy a new mobile phone.\n",
      "ans: #Person2# wants to buy a new mobile phone from #Person1#.\n",
      "pred: Judy has a new job.\n",
      "ans: Frank got a new job and is telling Judy not only the heavy schedule but also the benefits of this job.\n",
      "pred: Judy has a new job.\n",
      "ans: Frank explains to Judy the reason why he took a job at the Post office is that the government offers excellent health insurance benefits for its employees.\n",
      "pred: Judy has a new job.\n",
      "ans: Frank describes his new job's schedule and insurance at the Post Office to Judy.\n",
      "pred: #Person1#: I'm a secretary. #Person2#: I'm a doctor. #Person1#: I'm a secretary. #Person2#: I'm a secretary.\n",
      "ans: #Person2# is describing the educational background and previous working experience to #Person1# in a job interview.\n",
      "pred: #Person1#: I'm a secretary. #Person2#: I'm a doctor. #Person1#: I'm a secretary. #Person2#: I'm a secretary.\n",
      "ans: #Person2# is being interviewed by #Person1#. #Person2# is equipped with a bunch of valuable office skills.\n",
      "pred: #Person1#: I'm a secretary. #Person2#: I'm a doctor. #Person1#: I'm a secretary. #Person2#: I'm a secretary.\n",
      "ans: #Person1# asks about #Person2#'s special skills, training, previous working experience and other qualification for the job.\n",
      "pred: #Person1#: I'm sorry, but I'm not sure what you ordered.\n",
      "ans: #Person1# is not satisfied with the steak and #Person2# will change it.\n",
      "pred: #Person1#: I'm sorry, but I'm not sure what you ordered.\n",
      "ans: #Person2# will change a steak for #Person1# as that one doesn't satisfy #Person1#.\n",
      "pred: #Person1#: I'm sorry, but I'm not sure what you ordered.\n",
      "ans: #Person1# is not satisfied with #Person1#'s steak and asks to change one, and #Person2# agrees.\n",
      "pred: Tom's novel has won the Nobel Prize.\n",
      "ans: #Person1# congratulates Tom for achieving the Nobel Prize.\n",
      "pred: Tom's novel has won the Nobel Prize.\n",
      "ans: #Person1# tells Tom that his novel has won the Nobel Prize.\n",
      "pred: Tom's novel has won the Nobel Prize.\n",
      "ans: #Person2# tells Tom he won the Nobel Prize.\n",
      "pred: Obtain a job in the automotive industry.\n",
      "ans: #Person1# is interviewing #Person2# about #Person2#'s ability and previous experience.\n",
      "pred: Obtain a job in the automotive industry.\n",
      "ans: #Person1# asks #Person2# about #Person2#'s capacities and past working experience during an interview.\n",
      "pred: Obtain a job in the automotive industry.\n",
      "ans: #Person1# asks #Person2# about #Person2#'s qualification for the job.\n",
      "pred: No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. \n",
      "ans: #Person1# and #Person2# are talking about some personal facts of drinking. #Person2# drinks a lot, while #Person1# cannot drink much for health reasons. They decide to have a drink together tomorrow night.\n",
      "pred: No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. \n",
      "ans: #Person2#, a heavy drinker, invites #Person1#, a light drinker to go out the next day. #Person2# chooses a place that has a special on pitchers.\n",
      "pred: No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. No, I don't drink much. \n",
      "ans: #Person1# and #Person2# talk about their drinking capacity and their drinking habits. They decide to have a drink together tomorrow night.\n",
      "pred: The weather report says it will be sunny all day.\n",
      "ans: May is helping her mother to do some preparation for the picnic.\n",
      "pred: The weather report says it will be sunny all day.\n",
      "ans: May's mother asks May for help in preparing for a picnic. May gives her a hand.\n",
      "pred: The weather report says it will be sunny all day.\n",
      "ans: Mom asks May to help to prepare for the picnic and May agrees.\n",
      "pred: #Person1#: Hello, Muriel Douglas.\n",
      "ans: Muriel Douglas and James meet each other and talk about what they have done during the holiday.\n",
      "pred: #Person1#: Hello, Muriel Douglas.\n",
      "ans: James and Muriel are talking while waiting for Susan, Muriel's associate. They talk about how they spent the holiday with their families.\n",
      "pred: #Person1#: Hello, Muriel Douglas.\n",
      "ans: Muriel Douglas and James send greetings and talk about their holiday before the meeting. Douglas stayed in L.A., while James went to Tahoe.\n",
      "pred: #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#\n",
      "ans: #Person1# wants to withdraw money from an ATM, but the ATM automatically transfers 10000 USD to the World Wildlife Foundation after confirming the withdrawal option. #Person1# gets mad and somehow locked in.\n",
      "pred: #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#\n",
      "ans: #Person1# run out of money because of a girl, and is withdrawing money from an ATM. But the ATM seems to go wrong and transfers #Person1#'s money to the World Wildlife Foundation, driving #Person1# crazy.\n",
      "pred: #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#: I have to withdraw money from the ATM. #Person1#: I have to withdraw money from the ATM. #Person2#\n",
      "ans: #Person1# is withdrawing money from an ATM. But the ATM wrongly transfers #Person1#'s money to the World Wildlife Foundation. It drives #Person1# crazy.\n",
      "pred: #Person1#: I am an outgoing person who likes to be with a lot of friends.\n",
      "ans: #Person2# tells #Person1# #Person2#'s communication strategy.\n",
      "pred: #Person1#: I am an outgoing person who likes to be with a lot of friends.\n",
      "ans: Since #Person2# is very social, #Person1# asks for the communication strategy.\n",
      "pred: #Person1#: I am an outgoing person who likes to be with a lot of friends.\n",
      "ans: #Person2# shares #Person2#'s communication strategy with #Person1#.\n",
      "pred: Person1#: I'm sorry, Mr. Polly.\n",
      "ans: Mr. Polly is tired and wants a break from work. #Person1# cannot buy a bottle of soft drink for him.\n",
      "pred: Person1#: I'm sorry, Mr. Polly.\n",
      "ans: Mr. Polly wants to get a break from work and he asks #Person1# to buy a drink for him, but #Person1# refuses.\n",
      "pred: Person1#: I'm sorry, Mr. Polly.\n",
      "ans: Mr. Polly asks #Person1#'s help to buy a drink, but #Person1# refuses.\n",
      "pred: #Person1: Hi, this is Francis. #Person2: Hi, this is Monica. I'm working on a financial report. I'm available from 1 PM to 4 PM on Friday afternoon.\n",
      "ans: Francis and Monica are discussing when to work on the financial report.\n",
      "pred: #Person1: Hi, this is Francis. #Person2: Hi, this is Monica. I'm working on a financial report. I'm available from 1 PM to 4 PM on Friday afternoon.\n",
      "ans: Francis and Monica manage to find time to work on a report together.\n",
      "pred: #Person1: Hi, this is Francis. #Person2: Hi, this is Monica. I'm working on a financial report. I'm available from 1 PM to 4 PM on Friday afternoon.\n",
      "ans: Francis and Monica negotiate on the time to work on the report.\n",
      "pred: Take the interview class.\n",
      "ans: #Person1# joins #Person2#'s interview workshop. They discuss the tips to improve their interview performance.\n",
      "pred: Take the interview class.\n",
      "ans: #Person1# takes an interview workshop. #Person2# offer #Person1# some useful tips on getting ready for an interview.\n",
      "pred: Take the interview class.\n",
      "ans: In the workshop, #Person2# offer #Person1# some suggestions on how to perform well in interviews.\n",
      "pred: The two of them will try to figure out how to express their feelings.\n",
      "ans: #Person1# and Mike are discussing what kind of emotion should be expressed by Mike in this play. They have different understandings.\n",
      "pred: The two of them will try to figure out how to express their feelings.\n",
      "ans: #Person1# and Mike have a disagreement on how to act out a scene. #Person1# proposes that Mike can try to act in #Person1#'s way.\n",
      "pred: The two of them will try to figure out how to express their feelings.\n",
      "ans: #Person1# wants Mike to act more angry, but Mike thinks he should act both angry and sad.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "def get_promp(sample):\n",
    "    dialogue = sample['dialogue']\n",
    "    summary = sample['summary']\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following conversation.\n",
    "    \n",
    "    {dialogue}\n",
    "    \n",
    "    Summary:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "all_pred = []\n",
    "all_ans = []\n",
    "for i in range(len(dataset['test'])):\n",
    "    prompt = get_promp(dataset['test'][i])\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    output = tokenizer.decode(\n",
    "        original_model.generate(\n",
    "            inputs[\"input_ids\"], \n",
    "            max_new_tokens=200,\n",
    "        )[0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    all_pred.append(output)\n",
    "    all_ans.append(dataset['test'][i]['summary'])\n",
    "    if i> 100:\n",
    "        break\n",
    "\n",
    "\n",
    "for i in range(len(all_pred)):\n",
    "    print(\"pred:\", all_pred[i])\n",
    "    print(\"ans:\", all_ans[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5f7df1b-2ff2-47b8-af5b-1cc3c1247649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2225d9bea64e61907a03d19f958d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sa5u24/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/sa5u24/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sa5u24/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf17dce11194cec9115abc8cbb7303b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a57f8ac101b4724abb3320a704e9e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eede755cc1d5496bbbac96b50dad4db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE: {'rouge1': 0.21274141070336455, 'rouge2': 0.05725557885416832, 'rougeL': 0.18563351545863377, 'rougeLsum': 0.18558622087298865}\n",
      "BLEU: {'bleu': 0.04355090180693124, 'precisions': [0.18707179028894846, 0.07311827956989247, 0.034887408816999685, 0.0075385119632907244], 'brevity_penalty': 1.0, 'length_ratio': 1.433390264730999, 'translation_length': 3357, 'reference_length': 2342}\n",
      "METEOR: {'meteor': 0.19492674781016342}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "# Load the metrics\n",
    "meteor = load(\"meteor\")\n",
    "bleu = load(\"bleu\")\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "rouge_results = rouge.compute(predictions=all_pred, references=all_ans)\n",
    "bleu_result = bleu.compute(predictions=all_pred, references=all_ans)\n",
    "meteor_result = meteor.compute(predictions=all_pred, references=all_ans)\n",
    "\n",
    "print(\"ROUGE:\", rouge_results)\n",
    "print(\"BLEU:\", bleu_result)\n",
    "print(\"METEOR:\", meteor_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f92cd-173c-435c-9bad-c5630f6de590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9a32d48-b600-4bca-b853-89c14f0416f7",
   "metadata": {},
   "source": [
    "LoRA Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3442607c-3dd1-440e-a9f4-7ab068932863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 884736\n",
      "all model parameters: 168246528\n",
      "percentage of trainable model parameters: 0.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa5u24/anaconda3/envs/lit_llama/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "# BitsAndBytesConfig int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model_name='google/flan-t5-base'\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "peft_model = get_peft_model(original_model, \n",
    "                            lora_config)\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(peft_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627ad023-08e4-4244-a837-fc8fc02c583c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maoshuang0\u001b[0m (\u001b[33maoshuang0-university-of-southampton\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sa5u24/safe_lora/wandb/run-20250124_233953-aibqhb0a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aoshuang0-university-of-southampton/huggingface/runs/aibqhb0a' target=\"_blank\">/home/sa5u24/safe_lora/temp</a></strong> to <a href='https://wandb.ai/aoshuang0-university-of-southampton/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aoshuang0-university-of-southampton/huggingface' target=\"_blank\">https://wandb.ai/aoshuang0-university-of-southampton/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aoshuang0-university-of-southampton/huggingface/runs/aibqhb0a' target=\"_blank\">https://wandb.ai/aoshuang0-university-of-southampton/huggingface/runs/aibqhb0a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [564/564 03:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>21.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.703800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.297300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.213100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.191900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.163700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.159200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.142500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.131100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.121400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.121100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.130300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.122500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.127000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=564, training_loss=1.0128511469414894, metrics={'train_runtime': 217.9416, 'train_samples_per_second': 20.648, 'train_steps_per_second': 2.588, 'total_flos': 3093638676480000.0, 'train_loss': 1.0128511469414894, 'epoch': 3.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = '/home/sa5u24/safe_lora/temp'\n",
    "\n",
    "def tokenize_function(example):\n",
    "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example\n",
    "\n",
    "# The dataset actually contains 3 diff splits: train, validation, test.\n",
    "# The tokenize_function code is handling all data across all splits in batches.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])\n",
    "\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    # auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=20,\n",
    "    # max_steps=1    \n",
    ")\n",
    "    \n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"test\"],\n",
    ")\n",
    "\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add700a7-ae0c-47e8-a800-2821f8f0425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/sa5u24/safe_lora/temp/tokenizer_config.json',\n",
       " '/home/sa5u24/safe_lora/temp/special_tokens_map.json',\n",
       " '/home/sa5u24/safe_lora/temp/spiece.model',\n",
       " '/home/sa5u24/safe_lora/temp/added_tokens.json',\n",
       " '/home/sa5u24/safe_lora/temp/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save path\n",
    "peft_model_path=\"/home/sa5u24/safe_lora/temp\"\n",
    "\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79905b-bb13-491c-98e2-5e85cab190ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c041e21-bf45-4e39-8bda-7672c2b1f72e",
   "metadata": {},
   "source": [
    "Inference for LoRA & zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e11b32-15cb-4e8d-a345-8a66d4af468b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa5u24/anaconda3/envs/lit_llama/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "model_name='google/flan-t5-base'\n",
    "peft_model_path=\"/home/sa5u24/safe_lora/temp\"\n",
    "\n",
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map = 'auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "                                       peft_model_path, \n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False,\n",
    "                                       )\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map = 'auto')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8e9090-09c4-44c1-8869-4752e8932cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_baseline_summaries</th>\n",
       "      <th>original_model_summaries</th>\n",
       "      <th>peft_model_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Person2# has trouble breathing. The doctor as...</td>\n",
       "      <td>Person1: Hello, how are you doing today?</td>\n",
       "      <td>#Person2# has been having trouble breathing la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Person1# invites Jimmy to go workout and pers...</td>\n",
       "      <td>#Person1#: Hey Jimmy. Let's go workout later t...</td>\n",
       "      <td>#Person1# and Jimmy are going to work out late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1# plans to stop eating unhealthy foods...</td>\n",
       "      <td>#Person1#: I'm trying to lose weight. #Person2...</td>\n",
       "      <td>#Person1# wants to stop eating unhealthy foods...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person2# believes in UFOs and can see them in...</td>\n",
       "      <td>#Person1#: I've never seen UFOs. #Person2#: I'...</td>\n",
       "      <td>#Person1# is skeptical of UFOs and asks #Perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person1# didn't go to school today. #Person2#...</td>\n",
       "      <td>Person1 didn't go to school today.</td>\n",
       "      <td>#Person1# doesn't want to go to school today. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>#Person2# tells #Person1# about a funny experi...</td>\n",
       "      <td>The story of the trip was a great one.</td>\n",
       "      <td>#Person2# and #Person2# travelled throughout I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>#Person2# has an interview schedule on Wednesd...</td>\n",
       "      <td>The manager will interview Person1 tomorrow at...</td>\n",
       "      <td>#Person2# is asked for an interview, but #Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>#Person1# wants to start a marathon and #Perso...</td>\n",
       "      <td>#Person1#: I'm a good runner.</td>\n",
       "      <td>#Person1# wants to run a marathon and #Person2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>#Person1# wants to research Christian and Izek...</td>\n",
       "      <td>The new working partner is a Christian.</td>\n",
       "      <td>#Person1# is doing an essay about Christian re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>#Person2# tells #Person1# some matters needing...</td>\n",
       "      <td>The room is nice.</td>\n",
       "      <td>#Person1# is talking about the room and the ru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             human_baseline_summaries  \\\n",
       "0   #Person2# has trouble breathing. The doctor as...   \n",
       "1   #Person1# invites Jimmy to go workout and pers...   \n",
       "2   #Person1# plans to stop eating unhealthy foods...   \n",
       "3   #Person2# believes in UFOs and can see them in...   \n",
       "4   #Person1# didn't go to school today. #Person2#...   \n",
       "..                                                ...   \n",
       "95  #Person2# tells #Person1# about a funny experi...   \n",
       "96  #Person2# has an interview schedule on Wednesd...   \n",
       "97  #Person1# wants to start a marathon and #Perso...   \n",
       "98  #Person1# wants to research Christian and Izek...   \n",
       "99  #Person2# tells #Person1# some matters needing...   \n",
       "\n",
       "                             original_model_summaries  \\\n",
       "0            Person1: Hello, how are you doing today?   \n",
       "1   #Person1#: Hey Jimmy. Let's go workout later t...   \n",
       "2   #Person1#: I'm trying to lose weight. #Person2...   \n",
       "3   #Person1#: I've never seen UFOs. #Person2#: I'...   \n",
       "4                  Person1 didn't go to school today.   \n",
       "..                                                ...   \n",
       "95             The story of the trip was a great one.   \n",
       "96  The manager will interview Person1 tomorrow at...   \n",
       "97                      #Person1#: I'm a good runner.   \n",
       "98            The new working partner is a Christian.   \n",
       "99                                  The room is nice.   \n",
       "\n",
       "                                 peft_model_summaries  \n",
       "0   #Person2# has been having trouble breathing la...  \n",
       "1   #Person1# and Jimmy are going to work out late...  \n",
       "2   #Person1# wants to stop eating unhealthy foods...  \n",
       "3   #Person1# is skeptical of UFOs and asks #Perso...  \n",
       "4   #Person1# doesn't want to go to school today. ...  \n",
       "..                                                ...  \n",
       "95  #Person2# and #Person2# travelled throughout I...  \n",
       "96  #Person2# is asked for an interview, but #Pers...  \n",
       "97  #Person1# wants to run a marathon and #Person2...  \n",
       "98  #Person1# is doing an essay about Christian re...  \n",
       "99  #Person1# is talking about the room and the ru...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues = dataset['validation'][0:100]['dialogue']\n",
    "human_baseline_summaries = dataset['validation'][0:100]['summary']\n",
    "\n",
    "original_model_summaries = []\n",
    "instruct_model_summaries = []\n",
    "peft_model_summaries = []\n",
    "\n",
    "for idx, dialogue in enumerate(dialogues):\n",
    "    prompt = f\"\"\"\n",
    "                Summarize the following conversation.\n",
    "                \n",
    "                {dialogue}\n",
    "                \n",
    "                Summary: \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "    \n",
    "    human_baseline_text_output = human_baseline_summaries[idx]\n",
    "    \n",
    "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    original_model_summaries.append(original_model_text_output)\n",
    "    peft_model_summaries.append(peft_model_text_output)\n",
    "\n",
    "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, peft_model_summaries))\n",
    " \n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'peft_model_summaries'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3674437-0a6a-43b4-8247-9e5e9eaeaed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.23842230536363485, 'rouge2': 0.07294566939878172, 'rougeL': 0.20724668243568395, 'rougeLsum': 0.20814136804327285}\n",
      "PEFT MODEL:\n",
      "{'rouge1': 0.41949794950199876, 'rouge2': 0.1638233292110518, 'rougeL': 0.3450237504669067, 'rougeLsum': 0.3456101094061006}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "\n",
    "print('PEFT MODEL:')\n",
    "print(peft_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c4998b-38ea-4022-9a41-f1db9646e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sa5u24/safe_lora\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50493b6-37c8-4021-b90a-754cb2b3f5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
